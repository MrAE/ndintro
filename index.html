<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .remark-slide-content {
        font-size: 1.5em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .yellow { color: #FF00FF; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 50%;
      }
    </style>


  <!-- load remark -->
  <script src="http://gnab.github.com/remark/downloads/remark-0.5.1.min.js" type="text/javascript"></script>

  <!-- load MathJax -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntil=configured"></script>

  <!-- Initialize (has to go in <script> tag **without** SRC attribute) -->
  <script type="text/javascript">
      // Create slideshow
      var slideshow = remark.create({
          // This BREAKS MathJax: 
          // highlightLanguage: 'Python'
      
          // You have to tag every code block with python, like so:
          //
          // ```python
          // def add(a, b):
          //     return a + b
          // ```
          
      });
      
      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });
      
      MathJax.Hub.Configured();
  </script>

  </head>
  <body>
    <textarea id="source">



class: center, middle, inverse

# [NeuroData](http://neurodata.io): 
## Enabling Petascale Neuroscience

<!-- ### Joshua T. Vogelstein -->
<!-- ### {[BME](http://bme.jhu.edu),[ICM](http://icm.jhu.edu),[CIS](http://cis.jhu.edu),[Kavli](http://kndi.jhu.edu)}@[jhu](http://jhu.edu) -->

<!-- #### e: [jovo@jhu.edu](mailto:jovo@jhu.edu) | w:  -->
<!-- ### [NeuroData.io](http://neurodata.io) -->



#### this talk: <http://docs.neurodata.io/intro>

---

### Please consider the following _Gedankenexperiment_ 

#### Experiment 1:  collect 10 images in a stack (~ 10 MB) &rarr; find all ~100 synapses

0. Store: Can store on local hard drive 
1. Look: Open in ImageJ on local computer
2. Pre-process: Manually align images & adjust contrast
3. Annotate: Manually label each synapse
4. Analyze: Plot them all in a 3D scatter plot

.center[
<img src="images/Denk04_fig.png" alt="Drawing" style="height: 200px;"/>
]
---

### Please consider another _Gedankenexperiment_ 

#### Experiment 2:  collect 10 K images in a stack (~10 TB) &rarr; find all 10 M synapses

0. Store: Data too large to store on local hard drive 
1. Look: Data too large to load into ImageJ on local computer
2. Pre-process: Takes too long to manually pre-process
3. Annotate: Takes even longer find  all synapses
4. Analyze: Can't really see what is going on when plotting 10M synapses

.center[
<img src="images/corrected2.png" alt="Drawing" style="height: 200px;"/>
]


---

### Opportunity: Datasets like this are emerging over the place

.center[
<iframe width="420" height="315" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]

- Modality: Serial Electron Microscopy 
- Resolution: 3 x 3 x 30 nm<sup>3</sup>
- Volume: 40 x 40 x 50 &mu;m<sup>3</sup>
- Size: ~1 TB

Note: the above video is from Kasthuri et al. (Cell, 2015)



---

### Challenge:  Can't perform any of the 5 steps to discovery

<img src="https://www.lucidchart.com/publicSegments/view/66139744-74a7-46ed-bc12-dc3b00ffcfee/image.png" alt="Drawing" style="width: 700px;"/>


---

### Challenge:  Can't perform any of the 5 steps to discovery


<img src="http://www.lucidchart.com/publicSegments/view/8ad4c441-67e3-42e5-98ab-2cf9edfa0af5/image.png" alt="Drawing" style="width: 750px;"/>


### Action: Meet computational needs to achieve each step

--

### Resolution: [NeuroData](http://neurodata.io)!



---

# Outline


- Motivation
  - 2 case studies
  - Same infrastructure supports both (and many more!)
- For each step:
  - Overview of the goals
  - Limitations of classical data analysis paradigm
  - Capabilities of NeuroData analysis paradigm
- Outcomes
  - 2 case studies
  - EM Image data sets
  - Volumetric annotation data sets 
  - Other data sets
- What next?

---


# 2 Case Studies

.pull-left[

<iframe width="336" height="189" src="https://www.youtube.com/embed/dS_ONoUrptg?rel=0" frameborder="0" allowfullscreen></iframe>

- Bock et al. (Science, 2011)
- TEM Camera Array
- 4 x 4 x 40 nm^3
- 450 x 350 x 50 micron^3
- Size: ~10 TB
- Question: Are synapses distributed uniformly in space?
]

.pull-right[
<iframe width="258" height="189" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>

- Kasthuri et al. (Cell, 2015)
- Serial EM
- 3 x 3 x 30 nm^3
- 40 x 40 x 50 micron^3
- Size: ~1 TB
- Question: It Peter's rule a good model?
]


---

## Case Study #1: Synapse Distribution

- ~8 million cubic microns
--

- => ~8 million synapses
--

- Manual labeling requires ~10 sec / synapse
--

- 60 sec x 60 min x 8 hrs x 250 days = 8 million seconds
--

- A person can find 8 million synapses working for 10 years
--

- But we're impatient, we want to do it .yellow[this week]
--

- Is the distribution of synapses uniform in space? 

--
___

### What would it take to find all synapses in a few days?




---

# Case Study #2: Peter's Rule


- 916 excitatory axons
--

- 1,036 dendritic spines
--

- 7,505 spine touches
--

- 1,037 synapses
--

- Is the probability of a synapse between an axon and dendrite dictated solely by  proximity?






---

# 5 Steps to Discovery


<img src="https://www.lucidchart.com/publicSegments/view/8ad4c441-67e3-42e5-98ab-2cf9edfa0af5/image.png" alt="Drawing" style="width: 800px;"/>




---

## For each step, we have trade-offs to make

<br />

| _Property_    | _Classical_ &nbsp;	| _NeuroData_ |
| :---          | :----: 	          |  :---: |
| Quality   	| &#10003;	          | &#10007;|
| Scalability	| &#10007; 	| &#10003; |
| Features   	| &#10003; 	| &#10007; |
| 1-clickiness| &#10007; 	| &#10003;|

--

### Note: The ideal system will include both classical and novel NeuroData methods, as they complement one another.

---


# Hardware Platform

<br></br>

| _Sub-Need_          | | _Reason_      | 
| :---                | --- | :----    |  
| Data intensive Cluster  &nbsp;  | | Store TBs       | 
| High-Performance  Cluster &nbsp;&nbsp;  | | Process TBs   | 
| Local Thin Client   | | Control them  &nbsp;&nbsp;| 



---

# Steps 1 & 2

.center[
<img src="https://www.lucidchart.com/publicSegments/view/fba203d1-b641-41fb-9b7a-4465a885a7ec/image.png" style="width: 700px;"/>
]

---

# Data Intensive Cluster

.center[
<img src="http://docs.neurodata.io/open-connectome/_images/ocp_cluster.png" style="width: 700px;"/>
]

- Head node serves as Web proxy and load balance
- Application Server nodes can perform cutout, propagate, and other Web-services
- Databases store Image DB and Tile Cache on SSD array
- All store & look functions run on this cluster

---

# S.1: Image Data Model


.pull-left[
## Pre: Image Stack
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/9/9f/Stack.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
## ND: [Django Model](http://docs.neurodata.io/open-connectome/sphinx/datamodel.html)
<img src="http://docs.neurodata.io/open-connectome/_images/datamodel_simple.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Dataset: contains all metadata required to efficiently store, visualize, and analyze data
- Project: database storing a collection of channels
- Token:  name for a project with associated permissions
- Channel: collection of tables, including  images & metadata 


---

# S.2: Image DB

.pull-left[
## Pre: Images on a disk
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/5/54/Crystal_Project_harddrive.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
## ND: [Image DB](http://docs.neurodata.io/open-connectome/)
<img src="https://upload.wikimedia.org/wikipedia/commons/d/da/Lebesgue-3d-step3.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Dense multi-dimensional spatial array partitioned into cuboids
- Space filling curve minimizes the number of accesses
- Multi-resolution pyramid for fast access at any zoom level


---

# S.3: LIM System

.pull-left[
## Pre: Excel file
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Microsoft_Excel_2013_logo.svg/2000px-Microsoft_Excel_2013_logo.svg.png" alt="Drawing" style="height: 125px;"/>
]]

.pull-right[
## ND: [LIMS](https://github.com/openconnectome/ocpmeta)
<img src="http://www.frontiersin.org/files/Articles/149964/fninf-09-00020-HTML/image_m/fninf-09-00020-t001.jpg" alt="Drawing" style="height: 125px;"/>
]


### How does ND work?
- Stores metadata associated with projects/channels
- Will integrate with Nature's [Scientific Data](http://www.nature.com/sdata/) and [HBP](https://www.humanbrainproject.eu/) 



---

# S.4: Geometry DB

.pull-left[
### Pre: Segmented Images
.center[
<img src="images/annotated.2.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
### ND: [RAMON](http://docs.neurodata.io/nddocs/ramon.html)
<img src="http://www.frontiersin.org/files/Articles/149964/fninf-09-00020-HTML/image_m/fninf-09-00020-t001.jpg" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Implementation of object data model
- Specifies the dictionary of semantic labels (eg, synapse)
- Each type has a number of features (eg, confidence) 
- Types have sub-types and can be hierarchically composed
- Facilitates efficient spatial+semantic queries 



---
# L.1: Tile Cache

.pull-left[
## Pre: Image DB
<img src="https://upload.wikimedia.org/wikipedia/commons/d/da/Lebesgue-3d-step3.png" alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: [Tile Cache](http://docs.neurodata.io/open-connectome/)
<img src="https://upload.wikimedia.org/wikipedia/commons/9/9f/Stack.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Dense multi-dimensional spatiall array partitioned into cuboids
- Space filling curve minimizes the number of accesses
- Multi-resolution pyramid for fast access at any zoom level



---
# L.2: Web-Viz


.pull-left[
## Pre: [CATMAID](http://catmaid.readthedocs.org/en/latest/)
<img src="http://catmaid.readthedocs.org/en/latest/_images/ortho_views.jpg" alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: [NeuroDataViz](https://github.com/openconnectome/neurodataviz)

<img src="images/ndviz.png" alt="Drawing" style="height: 150px;"/>

]

### How does ND work?
- Uses [Leaflet](http://leafletjs.com/) (so works on mobile)
- [Volumetric annotation overlays](http://brainviz1.cs.jhu.edu/ndv/kharris15apical/em,ramon_test/3/507/469/90/)
- [Multispectral blending](http://brainviz1.cs.jhu.edu/ndv/project/Aratome15c_S17_W10/1/5818/527/0/)
- [Time-series](http://openconnecto.me/ocp/viz/freeman14/)


---
# L.3: Extract Geometries



.pull-left[
## Pre: [Blender](https://www.blender.org/)
<img src="https://upload.wikimedia.org/wikipedia/commons/b/bf/Blender_2.76.png" alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: NeuroDataSurf

<img src="images/surf.png" alt="Drawing" style="height: 150px;"/>

]

### How will ND work?
- Extracts aribtrarily large surfaces/skeletons 
- Dynamically downsamples appropriate for screen resolution




---
# L.4: Extract Graphs

TODO(@jovo)



---

# Steps 3 & 4

.center[
<img src="https://www.lucidchart.com/publicSegments/view/7f4db298-f954-487c-b57d-3e0594dba1aa/image.png" style="width: 700px;"/>
]

---

# High Performance Cluster

.center[
### schematic of braincloud1 + brainstore + brainviz + intel phi + awesomer + awesome
]

- details for braincloud 1
- X cores, Y nodes
- 40 TB storage?
- Intel Phi?
- K80?





---
# Data Input/Output


<img src="http://docs.neurodata.io/CAJAL/_images/cajal_pipeline.jpg" alt="Drawing" style="height: 150px;"/>


<br />

- [CAJAL](docs.neurodata.io/CAJAL) MATLAB Toolbox
- [ndio](http://docs.neurodata.io/ndio/) Python Library
- Used to transfer data from Data-Intensive to High Performance Cluster and back




---
# Image Process

.center[
<img src="images/Denk04_fig.png" alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px " top="100px;"/>
<img src="images/raw.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; ; width: 50px" top="100px;"/>
<img src="images/corrected2.png"   alt="Drawing" style="height: 200px;"/>
]

1. Volume Reconstruct
2. Histogram Normalize
3. Register to Atlas


---
## I.1: Volume Reconstruct


.pull-left[
## Pre: Fiji = ImageJ
<img src="http://fiji.sc/_images/b/ba/Aligned-series-crop-512.gif"   alt="Drawing" style="position: fixed; right: 600px; height: 150px;"/>
]

.pull-right[
## ND: [Terastitcher](http://abria.github.io/TeraStitcher/)
<img src="https://raw.githubusercontent.com/abria/TeraStitcher/gh-pages/images/overview.png"   alt="Drawing" style="height: 150px;"/>
]

.pull-bottom[
### How does ND work?
- Terastitcher is a 3rd party tool
- Designed for very large images (TeraByte-sized or more)
- Parallel implementations available
- Web-service coming soon
]

---
## I.2: Histogram Normalize


.pull-left[
## Pre: Fiji = ImageJ
.center[
<img src="http://fiji.sc/_images/9/90/Brightness_contrast_pic.png"   alt="Drawing" style="height: 150px;"/>
]
<br />
]

.pull-right[
## ND: [dmg](http://www.cs.jhu.edu/~misha/Code/DMG/Version4.5/) + [gdf](http://arxiv.org/pdf/1506.02079v1.pdf)
<img src="images/original_zy.jpg" alt="Drawing" style="height: 150px;"/>
<img src="images/screened_zy.jpg" alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
- Matches histograms across tiles in plane
- Removes high frequency flickering
- Keeps low frequency content
- Web-service coming soon



---
## I.3: Register to Atlas


.pull-left[
## Pre: [MRIStudio](https://www.mristudio.org/)
<img src="http://www.mri-resource.kennedykrieger.org/_/rsrc/1359758836283/software/software_roieditor.png"   alt="Drawing" style="height: 200px;"/>
]

.pull-right[
## ND: [ndreg](https://github.com/openconnectome/ndreg)
<img src="images/ndreg.png"   alt="Drawing" style="height: 200px;"/>
]


### How does ND work?
- Resample CLARITY brain to atlas resolution
- Semi-automatically learn brain mask
- Automatically extract altas mask
- Uses [LDDMM](http://www.cis.jhu.edu/software/lddmm-volume/) to align masks


---
# Scene Parse

.center[
<img src="images/raw.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px" top="100px;"/>
<img src="images/annotated.2.png"    alt="Drawing" style="height: 200px;"/>
]

1. Label
1. Train
1. Test
1. Deploy

---
## S.1: Label


.pull-left[
## Pre: [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php)
.center[
<img src="http://www.itksnap.org/pmwiki/uploads/Main/Image1.png"   alt="Drawing" style="height: 175px;"/>
]]

.pull-right[
## ND: ITK-SNAP + [manno](docs.neurodata.io/manno)

<img src="http://docs.neurodata.io/manno/_images/manno_itk_example.jpg"   alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. Identify ROI
2. Use CAJAL/ndio to download data
3. run `manno_getImage.m` to get image
4. Annotate using ITK-SNAP
5. Save annotations
5. run `manno_putAnno.m` to put annotation database

---
## S: Train



.pull-left[
## Pre: [ilastik](http://ilastik.org/)
<img src="http://ilastik.org/gallery/Figure2a.png"   alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: ilastic+CAJAL/ndio
<img src="http://ilastik.org/gallery/Figure2a.png"   alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. Identify ROI
2. Use CAJAL/ndio to download hdf5 file
3. Choose features + scales
4. Run random forest classifier
5. Save ilastik project




---
## S: Test



.pull-left[
## Pre: Custom MATLAB?
<br /><br /><br /><br /><br />


]

.pull-right[
## ND: [macho](http://docs.neurodata.io/macho/)
<img src="http://docs.neurodata.io/macho/_images/macho_example.png"    alt="Drawing" style="height: 150px; position=right"/>
]


### How does ND work?
- Visualize results
- Plot ROC curves
- Sweep over hyper-parameters
- Cross-validate to choose optimal settings



---
## S: Deploy



.pull-left[
## Pre: Horrible bash
<br /><br /><br /><br /><br />
]


.pull-right[
## ND: [LONI Pipeline](http://pipeline.bmap.ucla.edu/)
<img src="http://www.frontiersin.org/files/Articles/609/fninf-03-022/image_m/fninf-03-022-g002.jpg"    alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. GUI to generate workflow connecting modules
2. Each module calls a single executable
3. Get Cubes for each worker node
4. Each node processes data and spits out its answer
6. CAJAL then merges them back together
7. And sends back to database




---
# Analyze

.center[
<img src="images/annotated.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px" top="100px;"/>
<img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Answer_to_Life.png"    alt="Drawing" style="height: 200px;"/>
]

1. Query Objects
2. Spatial Statistics
2. Graph Statistics
3. Model Check

---
## A.1: Query Objects


.pull-left[
## Pre: Excel + MATLAB?
<br /><br /><br /><br /><br /><br /><br />
]


.pull-right[
## ND: CAJAL/ndio
<img src="images/vesicle_count.png"    alt="Drawing" style="height: 200px;"/>
]


### How does ND work?
1. Use CAJAL/ndio to download & count all synapses
1. [live ndio binder](http://app.mybinder.org/2805214324/notebooks/kasthuri-statistics/Count%20Vesicles.ipynb)


---
## A.2: Geometry Statistics


.pull-left[
## Pre: Spatial Stats
]


.pull-right[
## ND:  Spatial Stats
]



### How does ND work?


---
## A.3: Graph Statistics


.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/commons/9/9b/Social_Network_Analysis_Visualization.png"    alt="Drawing" style="height: 150px; "/>
]

<br />

.pull-left[
## Pre: igraph
]


.pull-right[
## ND: FlashGraph
]


### How does ND work?
1. Semi-external memory
2. Store nodes in RAM, edges on SSDs
3. Can process 1B vertex & 100B edge graphs
4. Faster & cheaper than large clusters
5. Supports graph traversal & matrix operations


---
## A.4:  Model Check

.pull-left[
## Pre: P-value
]


.pull-right[
## ND: Same old, same old
]


### How does ND work?
1. Chi-squared test
2. p &#8776; 0


---


# Case Study #1

.pull-right[
.center[
<img src="images/rob2.png"    alt="Drawing" style="height: 150px; "/>
<img src="images/3D.png"    alt="Drawing" style="height: 150px; "/>
<img src="images/2Dproj.png"    alt="Drawing" style="width: 250px; "/>
]]

.pull-left[
1. find all synapses
2. plot 1% of them in 3D scatter plot
1. Mask out regions that cannot have synapses
1. Partition volume into cuboids
2. Count # of elements / cuboid
3. Normalize by volume of cuboid not masked
4. Plot normalized volume in 3D scatter plot
5. Plot marginals
6. Report p-value
1. live python notebook coming soon...
]



--- 

# Case Study #2

- live python notebook coming soon...



---

# Discussion: NeuroData!


### We make the following open science contributions:
- reference datasets in a variety of modalities
- reference pipelines for operating on such data
- Web-services for data access
- Cluster configuration
- A cloud computing stack to facilitate analysis
- Detailed specs for plugging in different routines
- Data derivatives at all stages of analysis

--

#### It is now easier to:
- Answer questions the require scale
- Engage complementary expertise
- Bridge across scales and modalities 
- Reproduce results

---

# Case Study #3: the numbers


### What would it take to estimate a 100 M vertex graph from multiple 1 PB dataset?




#### Note: we are working towards supporting the 2nd question, we currently can do the 1st.


---

# Next steps

- Put it all together
- Release rest of code & documentation
- Apply to other domains & questions
- We work together!

--

<!-- # Sneak Peak -->

<img src="images/modalities.png"    alt="Drawing" style="width: 800px; "/>

---


# Hackathon

<img src="images/hack.png"    alt="Drawing" style="width: 800px; "/>

---
class:   center

# NeuroData Peeps

<br />
<img src="https://cloud.githubusercontent.com/assets/4883288/10324878/2c461eca-6c5b-11e5-9735-1dcf6d609c61.png"  alt="Drawing" style="width: 650px; "/>

---
class:   inverse, center


<br /><br>

<!-- ### Funding &nbsp;&nbsp;&nbsp;&nbsp;   -->


_____

Funding


NIH: TRA

NIH/NSF:  {BIGDATA, CRCNS} 

DARPA: {XDATA,GRAPHS,SIMPLEX} 


____

f: [docs](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io) 

w: [neurodata.io](http://neurodata.io)


____

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>