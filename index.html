<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .remark-slide-content {
        font-size: 1.5em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .yellow { color: #FF00FF; }
      .green { color: #00CC00; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 50%;
      }
    </style>


  <!-- load remark -->
  <script src="http://gnab.github.com/remark/downloads/remark-0.5.1.min.js" type="text/javascript"></script>

  <!-- load MathJax -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntil=configured"></script>

  <!-- Initialize (has to go in <script> tag **without** SRC attribute) -->
  <script type="text/javascript">
      // Create slideshow
      var slideshow = remark.create({
          // This BREAKS MathJax: 
          // highlightLanguage: 'Python'
      
          // You have to tag every code block with python, like so:
          //
          // ```python
          // def add(a, b):
          //     return a + b
          // ```
          
      });
      
      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });
      
      MathJax.Hub.Configured();
  </script>

  </head>
  <body>
    <textarea id="source">



class: center, middle, inverse

# [Open Connectome Project](http://openconnecto.me) & [NeuroData](http://neurodata.io): 
## Enabling Petascale Neuroscience

<!-- ### Joshua T. Vogelstein -->
<!-- ### {[BME](http://bme.jhu.edu),[ICM](http://icm.jhu.edu),[CIS](http://cis.jhu.edu),[Kavli](http://kndi.jhu.edu)}@[jhu](http://jhu.edu) -->

<!-- #### e: [jovo@jhu.edu](mailto:jovo@jhu.edu) | w:  -->
<!-- ### [NeuroData.io](http://neurodata.io) -->



#### this talk: <http://docs.neurodata.io/intro>

---

### Please consider the following _Gedankenexperiment_ 

#### Experiment 1:  collect 10 images in a stack (~ 10 MB) &rarr; find all ~100 synapses

0. Store: Can store on local hard drive 
1. Look: Open in ImageJ on local computer
2. Pre-process: Manually align images & adjust contrast
3. Parse: Manually label each synapse
4. Analyze: Plot them all in a 3D scatter plot

.center[
<img src="images/Denk04_fig.png" alt="Drawing" style="height: 200px;"/>
]
---

### Please consider another _Gedankenexperiment_ 

#### Experiment 2:  collect 10 K images in a stack (~10 TB) &rarr; find all 10 M synapses

0. Store: Data too large to store on local hard drive 
1. Look: Data too large to load into ImageJ on local computer
2. Pre-process: Takes too long to manually pre-process
3. Parse: Takes even longer find  all synapses
4. Analyze: Can't really see what is going on when plotting 10M synapses

.center[
<img src="images/corrected2.png" alt="Drawing" style="height: 200px;"/>
]


---

### Opportunity: Datasets like this are emerging over the place

.center[
<iframe width="420" height="315" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]

- Modality: Serial Electron Microscopy 
- Resolution: 3 x 3 x 30 nm<sup>3</sup>
- Volume: 40 x 40 x 50 &mu;m<sup>3</sup>
- Size: ~1 TB

Note: the above video is from Kasthuri et al. (Cell, 2015)



---

### Challenge:  Can't perform any of the 5 steps to discovery

<img src="https://www.lucidchart.com/publicSegments/view/2adae4b6-6cc4-4b6f-9ee7-ff6fc4794470/image.png" alt="Drawing" style="width: 700px;"/>


---

### Challenge:  Can't perform any of the 5 steps to discovery


<img src="https://www.lucidchart.com/publicSegments/view/5df22a12-6d41-4342-9bee-b58329daeb2b/image.png" alt="Drawing" style="width: 750px;"/>


### Action: Meet computational needs to achieve each step

--

### Resolution: [NeuroData](http://neurodata.io)!



---

# Outline


- Motivation
  - 2 case studies
  - Same infrastructure supports both (and many more!)
- For each step:
  - Overview of the goals
  - Limitations of classical data analysis paradigm
  - Capabilities of NeuroData analysis paradigm
- Outcomes
  - 2 case studies
  - EM Image data sets
  - Volumetric annotation data sets 
  - Other data sets
- What next?



---

## Case Study #1: Synapse Distribution


.center[
<iframe width="403" height="227" src="https://www.youtube.com/embed/dS_ONoUrptg?rel=0" frameborder="0" allowfullscreen></iframe>
]
- Bock et al. (Science, 2011)
- TEM Camera Array
- 4 x 4 x 40 nm^3
- 450 x 350 x 50 micron^3
- Size: ~10 TB
- Question: Are synapses distributed uniformly in space?


---

## Case Study #1: Synapse Distribution


- ~8 million cubic microns
--

- => ~8 million synapses
--

- Manual labeling requires ~10 sec / synapse
--

- 60 sec x 60 min x 8 hrs x 250 days = 8 million seconds
--

- A person can find 8 million synapses working for 10 years
--

- Is the distribution of synapses uniform in space? 
--

- But we're impatient, we want to do it .yellow[this week]






---

# Case Study #2: Peter's Rule


.center[
<iframe width="310" height="227" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]

- Kasthuri et al. (Cell, 2015)
- Serial EM
- 3 x 3 x 30 nm^3
- 40 x 40 x 50 micron^3
- Size: ~1 TB
- Question: It Peter's rule a good model?



---

# Case Study #2: Peter's Rule


- 916 excitatory axons
--

- 1,036 dendritic spines
--

- 7,505 spine touches
--

- 1,037 synapses
--

- Is the probability of a synapse between an axon and dendrite dictated solely by  proximity?






---

# 5 Steps to Discovery


<img src="https://www.lucidchart.com/publicSegments/view/5df22a12-6d41-4342-9bee-b58329daeb2b/image.png" alt="Drawing" style="width: 800px;"/>




---

## For each step, we have trade-offs to make

<br />

| _Property_    | _Classical_ &nbsp;| _NeuroData_ &nbsp; | _Both_ |
| :---          | :----: 			| :---: 			| :---: |
| Quality   	| .green[&check;]	| .red[&cross;] 	| .green[&check;] |
| Scalability	| .red[&cross;] 	| .green[&check;]	| .green[&check;] |
| Capabilities   	| .green[&check;] 	| .red[&cross;] 	| .green[&check;] |
| 1-clickiness 	| .red[&cross;] 	| .green[&check;] 	| .green[&check;] |


--

### Note: The ideal system will include both classical and novel NeuroData methods, as they complement one another.



---

# Steps 1 & 2

.center[
<img src="https://www.lucidchart.com/publicSegments/view/ca288553-aa5a-4b69-b3c9-16e098b45a6d/image.png" style="width: 700px;"/>
]



---

# Data Intensive Cluster

.center[
<img src="http://docs.neurodata.io/open-connectome/_images/ocp_cluster.png" style="width: 700px;"/>
]

- Head node serves as Web proxy and load balance
- Application Server nodes can perform cutout, propagate, and other Web-services
- Databases store Image DB and Tile Cache on SSD array


---

# S.1A: Image Data Model


.pull-left[
## Pre: Image Stack
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/9/9f/Stack.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
## ND: [Image Data Model](http://docs.neurodata.io/open-connectome/sphinx/datamodel.html)
<img src="http://docs.neurodata.io/open-connectome/_images/datamodel_simple.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Dataset: contains all metadata required to efficiently store, visualize, and analyze data
- Project: database storing a collection of channels
- Token:  name for a project with associated permissions
- Channel: collection of tables, including  images & metadata 


---

# S.2A: Image Database

.pull-left[
## Pre: Images on a disk
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/5/54/Crystal_Project_harddrive.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
## ND: [Image DB](http://docs.neurodata.io/open-connectome/)
<img src="https://upload.wikimedia.org/wikipedia/commons/d/da/Lebesgue-3d-step3.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
  - Ingest
  - Cutout (volume, XY, YZ, XZ, nifti)
  - Overlay
  - Propagate
  - Histogram Window
  - 3rd Party Support (CATMAID, Viking, KNOSSOS, etc.)



---

# S.3A: Image Data Management

.pull-left[
## Pre: Excel file
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Microsoft_Excel_2013_logo.svg/2000px-Microsoft_Excel_2013_logo.svg.png" alt="Drawing" style="height: 125px;"/>
]
<br />
]

.pull-right[
## ND: [Data Mgmt](https://github.com/openconnectome/ocpmeta)
<img src="images/LIMS.png" alt="Drawing" style="width: 300px;"/>
]


### How does ND work?
  - Create/Edit/Delete Dataset
  - Create/Edit/Delete Project
  - Create/Delete Channel
  - Browse Public Tokens
  - Get Project Info



---

# S.1B: Anno. Object Data Model

.pull-left[
### Pre: RedCyl...-FINAL...*_?*
.center[
<img src="images/bobby.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
### ND: [RAMON](http://docs.neurodata.io/nddocs/ramon.html)
<img src="https://github.com/openconnectome/nddocs/raw/gh-pages/images/ramon_overview.jpg" alt="Drawing" style="height: 150px;"/>
] <br />



### How does ND work?
- Specifies the dictionary of semantic labels (eg, synapse)
- Each type has a number of features (eg, confidence) 
- Types have sub-types and can be hierarchically composed
- Stores all desired metadata per object
- Facilitates efficient spatial+semantic queries 



---

# S.2B: Anno. Object DB

.pull-left[
### Pre: Segmented Images
.center[
<img src="images/annotated.2.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
### ND: [AnnoDB](http://docs.neurodata.io/open-connectome/api/ramon_api.html)
<img src="http://www.frontiersin.org/files/Articles/149964/fninf-09-00020-HTML/image_m/fninf-09-00020-t001.jpg" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
  - Stores annotation objects & metadata
  - Merge
  - Graph Generate
  - Get Skeleton  



---

# S.3B: Anno. Object Management

.pull-left[
### Pre: Segmented Images
.center[
<img src="images/bobby.png" alt="Drawing" style="height: 150px;"/>
]]

.pull-right[
### ND: [Anno Object Mgmt](http://docs.neurodata.io/open-connectome/api/ramon_api.html)
<img src="http://www.frontiersin.org/files/Articles/149964/fninf-09-00020-HTML/image_m/fninf-09-00020-t001.jpg" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?

  - Set Field
  - Get Field
  - Query
  - Get Annotation
  - Post Annotation
  - Undo

---
## L.1: Content Distribution Network

.pull-left[
## Pre: Image DB
<img src="images/NCDN.png" alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: [Tile Cache](http://docs.neurodata.io/open-connectome/)
<img src="images/CDN.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Tile cache loads images on SSDs
- Pre-fetches data
- Can cache locally as large as possible
- Deploy anywhere in the world to achieve 60 Hz rates


---
# L.2: Web-Viz


.pull-left[
## Pre: [CATMAID](http://catmaid.readthedocs.org/en/latest/)
<img src="http://catmaid.readthedocs.org/en/latest/_images/ortho_views.jpg" alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: [NeuroDataViz](https://github.com/openconnectome/neurodataviz)
<img src="images/ndviz.png" alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- Uses [Leaflet](http://leafletjs.com/) (so works on mobile)
- [Volumetric annotation overlays](http://brainviz1.cs.jhu.edu/ndv/kharris15apical/em,ramon_test/3/507/469/90/)
- [Multispectral blending](http://brainviz1.cs.jhu.edu/ndv/project/Aratome15c_S17_W10/1/5818/527/0/)
- [Time-series](http://openconnecto.me/ocp/viz/freeman14/)
- Image & Anno. Metadata






---
## L.3: Query Objects


.pull-left[
## Pre: Excel + MATLAB?
.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Microsoft_Excel_2013_logo.svg/2000px-Microsoft_Excel_2013_logo.svg.png" alt="Drawing" style="height: 125px;"/>
]
]


.pull-right[
## ND: [CAJAL](docs.neurodata.io/CAJAL)/[ndio](http://docs.neurodata.io/ndio/)
<img src="http://docs.neurodata.io/CAJAL/_images/cajal_pipeline.jpg" alt="Drawing" style="width: 300px;"/>
<br /><br /><br />
]


### How does ND work?
1. CAJAL MATLAB Toolbox
1. ndio Python Library
1. Wraps all Web-services 

---

# Steps 3 & 4

.center[
<img src="https://www.lucidchart.com/publicSegments/view/41779086-5238-4317-a1d5-acd22e9dab06/image.png" style="width: 700px;"/>
]

---

# High Performance Computing

.center[
### schematic of braincloud1 + brainstore + brainviz + intel phi + awesomer + awesome
]

- Brainapps
- Brain Cloud
- Awesome
- Awesomer
- Intel Phi
- K80






---
# Image Process

.center[
<img src="images/Denk04_fig.png" alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px " top="100px;"/>
<img src="images/raw.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; ; width: 50px" top="100px;"/>
<img src="images/corrected2.png"   alt="Drawing" style="height: 200px;"/>
]

1. Volume Reconstruct
2.  Histogram Normalize
3. Register to Atlas


---
## I.1: Volume Reconstruct


.pull-left[
## Pre: Fiji = ImageJ
<img src="http://fiji.sc/_images/b/ba/Aligned-series-crop-512.gif"   alt="Drawing" style="position: fixed; right: 600px; height: 150px;"/>
<br /><br /><br /><br /><br />
]

.pull-right[
## ND: 3rd Party Apps
<img src="https://raw.githubusercontent.com/abria/TeraStitcher/gh-pages/images/overview.png"   alt="Drawing" style="height: 150px;"/>
]

### How does ND work?
- [Terastitcher](http://abria.github.io/TeraStitcher/)
- [Reconstruct](http://synapses.clm.utexas.edu/tools/reconstruct/reconstruct.stm)
- [Fiji Elastic Aligment & Montage](http://fiji.sc/Elastic_Alignment_and_Montage)


---
## I.2: Histogram Normalize


.pull-left[
## Pre: Fiji = ImageJ
.center[
<img src="http://fiji.sc/_images/9/90/Brightness_contrast_pic.png"   alt="Drawing" style="height: 150px;"/>
]
<br />
]

.pull-right[
## ND: [dmg](http://www.cs.jhu.edu/~misha/Code/DMG/Version4.5/) + [gdf](http://arxiv.org/pdf/1506.02079v1.pdf)
<img src="images/original_zy.jpg" alt="Drawing" style="height: 150px;"/>
<img src="images/screened_zy.jpg" alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
- 2D via dmg
  - Stitching
  - Smoothing/Sharpening/High-Low Composting 
- 3D via gdf (Gradient Domain Fusion)
- Web-service coming soon



---
## I.3: Register to Atlas


.pull-left[
## Pre: [MRIStudio](https://www.mristudio.org/)
<img src="http://www.mri-resource.kennedykrieger.org/_/rsrc/1359758836283/software/software_roieditor.png"   alt="Drawing" style="height: 200px;"/>
]

.pull-right[
## ND: [ndreg](https://github.com/openconnectome/ndreg)
<img src="images/ndreg.png"   alt="Drawing" style="height: 200px;"/>
]


### How does ND work?
- Rigid, Affine, and Nonlinear ([LDDMM](http://www.cis.jhu.edu/software/lddmm-volume/))
- Can apply to landmarks, masks, or images
- Includes automatic masking

---
# Scene Parse

.center[
<img src="images/raw.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px" top="100px;"/>
<img src="images/annotated.2.png"    alt="Drawing" style="height: 200px;"/>
]

1. Label
1. Train
1. Test
1. Deploy

---
## S.1: Label


.pull-left[
## Pre: [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php)
.center[
<img src="http://www.itksnap.org/pmwiki/uploads/Main/Image1.png"   alt="Drawing" style="height: 175px;"/>
]]

.pull-right[
## ND: ITK-SNAP + [manno](docs.neurodata.io/manno)

<img src="http://docs.neurodata.io/manno/_images/manno_itk_example.jpg"   alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. Identify ROI
2. Use CAJAL/ndio to download data
3. run `manno_getImage.m` to get image
4. Annotate using ITK-SNAP
5. Save annotations
5. run `manno_putAnno.m` to put annotation database

---
## S: Train



.pull-left[
## Pre: [ilastik](http://ilastik.org/)
<img src="http://ilastik.org/gallery/Figure2a.png"   alt="Drawing" style="height: 150px;"/>
]

.pull-right[
## ND: ilastic+CAJAL/ndio
<img src="http://ilastik.org/gallery/Figure2a.png"   alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. Identify ROI
2. Use CAJAL/ndio to download hdf5 file
3. Choose features + scales
4. Run random forest classifier
5. Save ilastik project




---
## S: Test



.pull-left[
## Pre: Custom MATLAB?
<br /><br /><br /><br /><br />


]

.pull-right[
## ND: [macho](http://docs.neurodata.io/macho/)
<img src="http://docs.neurodata.io/macho/_images/macho_example.png"    alt="Drawing" style="height: 150px; position=right"/>
]


### How does ND work?
- Visualize results
- Plot ROC curves
- Sweep over hyper-parameters
- Cross-validate to choose optimal settings



---
## S: Deploy



.pull-left[
## Pre: Horrible bash
<br /><br /><br /><br /><br />
]


.pull-right[
## ND: [LONI Pipeline](http://pipeline.bmap.ucla.edu/)
<img src="http://www.frontiersin.org/files/Articles/609/fninf-03-022/image_m/fninf-03-022-g002.jpg"    alt="Drawing" style="height: 150px;"/>
]


### How does ND work?
1. GUI to generate workflow connecting modules
2. Each module calls a single executable
3. Get Cubes for each worker node
4. Each node processes data and spits out its answer
6. CAJAL then merges them back together
7. And sends back to database




---
# Analyze

.center[
<img src="https://www.lucidchart.com/publicSegments/view/ce86ae90-ffff-4680-9f53-03edb4fd8bc3/image.png"    alt="Drawing" style="height: 200px;"/>
]

.center[
<img src="images/annotated.2.png"    alt="Drawing" style="height: 200px;"/>
<img src="http://etc.usf.edu/clipart/70300/70317/70317_258_c-2b_s_lg.gif"    alt="Drawing" style="height: 200px; width: 50px" top="100px;"/>
<img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Answer_to_Life.png"    alt="Drawing" style="height: 200px;"/>
]





---
## A.2: Geometric Statistics


.pull-left[
## Pre: Rstudio/Anaconda
<img src="http://www.thinkr.spatialfiltering.com/images/Rlogo.png"    alt="Drawing" style="height: 100px;"/>
<img src="images/anaconda_logo.png"    alt="Drawing" style="height: 100px;"/>
]


.pull-right[
## ND:  Scalable Stats
<img src="http://www.programmableweb.com/sites/default/files/github-jupyter.jpg"    alt="Drawing" style="height: 100px;"/>
<img src="images/mybinder.png"    alt="Drawing" style="height: 100px;"/>
]


### How does ND work?

- [Vector Explorer](https://github.com/ikuznet1/data-analytics-website/): Web-service for EDA 
- [Live demo's](http://app.mybinder.org/2473862297/tree) using [mybinder](http://mybinder.org/), [jupyter](http://jupyter.org/), & [github](https://github.com/)
- Demo's use our & others' open source [R](https://www.r-project.org/) & [Python](https://www.python.org/) libraries 

---
## A.3:  Graph Statistics



.pull-left[
## Pre: [igraph](http://igraph.org/)
<img src="http://igraph.org/img/igraph3.svg"    alt="Drawing" style="height: 100px; "/>
]


.pull-right[
## ND:  Graph Services
<img src="images/fg.png"    alt="Drawing" style="height: 100px; "/>
]


### How does ND work?
- [Download](http://openconnecto.me/graph-services/download/) 100s of different neurographs
- [Convert](http://openconnecto.me/graph-services/convert/) graphs between formats
- [m2g](http://m2g.io/) estimates graphs from diffusion MRI data
- [i2g](http://i2g.io/) estimates graphs from EM data
- [Graph Explorer](http://128.220.176.8/ge/) for Web-analysis (calls igraph)
- [FlashR](https://github.com/openconnectome/FlashR) for new statistical methods for graph analysis
- [FlashGraph](http://www.flashgraph.net/) for scalable analyses (> 1 B vertices)


---
## A.4:  "Publish"

.pull-left[
## Pre: arXiv/FigShare
<img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/Arxiv.png"    alt="Drawing" style="height: 100px; "/>
<img src="https://pbs.twimg.com/profile_images/1756579306/spiralsticker.png"    alt="Drawing" style="height: 100px; "/>
]


.pull-right[
## ND: ND Publish
<img src="images/ndviz.png" alt="Drawing" style="height: 100px;"/>
<img src="images/vesicle_count.png"    alt="Drawing" style="height: 100px;"/>
]


### How does ND work?
1. Create new dataset/project/channel
2. Upload all data & metadata
3. Share jupyter notebook in live binder containing analysis


---

# Results

- Case Study 1
- Case Study 2
- Other EM datasets
- Manually Parsed Scenes
- Other Modalities


---


### Case Study #1: Is synapse distribution uniform in space?

.pull-right[
.center[
<img src="images/rob2.png"    alt="Drawing" style="height: 150px; "/>
<img src="images/3D.png"    alt="Drawing" style="height: 150px; "/>
<img src="images/2Dproj.png"    alt="Drawing" style="width: 250px; "/>
]]

.pull-left[
1. find all synapses
2. plot 1% of them in 3D scatter plot
1. Mask out regions that cannot have synapses
1. Partition volume into cuboids
2. Count # of elements / cuboid
3. Normalize by volume of cuboid not masked
4. Plot normalized volume in 3D scatter plot
5. Plot marginals
6. Report p-value
1. live python notebook coming soon...
]



---

### Case Study #2: Does Peter's rule hold in a cortical graph?

1. extract attributed graph
2. define null distribution
4. determine test statistic
3. sample from null using igraph
4. compute test statistic on observed & sampled data
5. evaluate p-value
6. visualize samples from null for model checking purposes
1. live python notebook coming soon...


---

#  EM Datasets

| Species | Ref. |
| :---    | :---  |
| [C elegans, herma](http://openconnecto.me/herm-c-elegans) 
| [C elegans, male](http://openconnecto.me/male-c-elegans) 
| [C elegans, Pharynx](http://openconnecto.me/bhatla15) | Bhatla et al. Current Biology, 2015
| [P pacificus](http://openconnecto.me/bumbarger13) | Bumbarger et al. Cell, 2013
| [Drosophila Optic Medulla](http://openconnecto.me/takemura13) | Takemura et al. Nature, 2013
| [Drosophila larva](http://openconnecto.me/behaviotypes) | Vogelstein et al., Science, 2014
| [Hippocampus Neuropil](http://openconnecto.me/synapseweb) | Harris et al., Scientific Data, 2015
| [Mouse, V1](http://openconnecto.me/bock11/) | Bock et al., Nature, 2011
| [Mouse, S1](http://openconnecto.me/Kasthurietal2014) | Kasthuri et al., Cell, 2015


---

# Volumetric Annotation Datasets

- AC3
- AC4
- Kasthuri et al. (Cell, 2015)
- Harris et al. (Scientific Data, 2015)

---

# Other Modalities

- [Array Tomography](http://neurodata.io/modalities/at)
- [CLARITY](http://neurodata.io/modalities/clarity) 
- [Multi-modal MRI](http://neurodata.io/modalities/mri)
- X-Brain
- ExM
- Calcium Imaging



---

# Discussion

- Contributions
- Implications
- Next steps


---

# Open Science Contributions

- reference datasets in a variety of modalities
- reference pipelines for operating on such data
- Web-services for data access
- Computing configuration
- A cloud computing stack to facilitate analysis
- Detailed specs for plugging in different routines
- Data derivatives at all stages of analysis

--

#### Implications: it is now easier to:
- Answer questions the require scale
- Engage complementary expertise
- Bridge across scales and modalities 
- Reproduce results

---

# Case Study #3: the numbers


### Question: What would it take to estimate a 100 M vertex graph from multiple 1 PB dataset?

### Answer: NeuroData in the Cloud!





---

# Next steps

- Put it all together
- Release rest of code & documentation
- Apply to other domains & questions
- Amazon cluster
- We work together!


<img src="images/modalities.png"    alt="Drawing" style="width: 800px; "/>

---
class:   center

# NeuroData Family

<br />
<img src="https://cloud.githubusercontent.com/assets/4883288/10324878/2c461eca-6c5b-11e5-9735-1dcf6d609c61.png"  alt="Drawing" style="width: 650px; "/>

---
class:   inverse, center


<br /><br>

<!-- ### Funding &nbsp;&nbsp;&nbsp;&nbsp;   -->


_____

Funding


NIH: TRA

NIH/NSF:  {BIGDATA, CRCNS} 

DARPA: {XDATA,GRAPHS,SIMPLEX} 


____

f: [docs](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io) 

w: [neurodata.io](http://neurodata.io)


____

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>