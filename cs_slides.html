<!DOCTYPE html>
<html>
  <head>
    <link href="https://file.myfontastic.com/n6vo44Re5QaWo8oCKShBs7/icons.css" rel="stylesheet">
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- bower:css -->
    <!-- <link rel="stylesheet" href="/content/themes/jhu_id/bower_components/normalize-css/normalize.css"> -->
    <link rel="stylesheet" href="fonts/gentona/gentona.css">
    <link rel="stylesheet" href="fonts/titling-gothic/titling-gothic.css">
    <link rel="stylesheet" href="fonts/quadon/quadon.css">
    <link rel="stylesheet" href="fonts/arnhem/arnhem.css">
    <!-- endbower -->

    <title>NeuroData Intro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Varela+Round:regular,italic,bold,bolditalic);
      @import url(http://fonts.googleapis.com/css?family=Raleway:regular,italic,bold,bolditalic);

      body {
        font-family: 'gentona'; /* Varela Round */
      }
      /*      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
      }      */
      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
        font-weight: 400;
        margin-bottom: 0;
      }

      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .remark-slide-content h4 { font-size: 1.4em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .navbar {
        position: absolute;
        float: center;
        top: 0em;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .navbar a {
        color: #A7A7A7;
      }
      .bbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .bbar a {
        color: #A7A7A7;
      }
      .btn {
        background: #424242;
        height: 2em;
      }
      .remark-slide-content {
        font-size: 1.5em;
        background: #272822;
        color: white;
      }
      li p { line-height: 1.25em; }
      .r { color: #fa0000; }
      .y { color: #FFFF00; }
      .pink { color: #FF87F3;}
      .orange { color: #FFA500;}
      .g { color: #00CC00; }
      .blue { color: #75E9FF;}
      .purple { color: #A149A9;}
      .large { font-size: 2em; }
      .black { color: black; background-color: white;}
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #424242;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
/*      .pull-left {
        float: left;
        width: 47%;
      }*/
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .small {
        font-size: 0.8em;
      }
/*      .pull-right {
        float: right;
        width: 47%;
      }*/
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .bottom {
        position: absolute;
        bottom: 35px;
        left: 13px;
        font-family: 'Yanone Kaffeesatz';
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: white;
        color: white;
        text-shadow: 0 0 20px #333;
      }
      .inverse p {
        color: white;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }
      #frame { zoom: 0.75; -moz-transform: scale(0.75); -moz-transform-origin: 0 0; }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-child {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 50%;
      }
      .task {
        float: right;
        font-size: 0.9em;
        padding-top: 0.6em;
      }

    </style>
  </head>
  <body onload="var slideshow = remark.create();">
    <textarea id="source">



class: center, middle

# [NeuroData](http://neurodata.io):
## Enabling Petascale Neuroscience

### Computer Science 

<!-- ### Joshua T. Vogelstein -->
<!-- ### {[BME](http://bme.jhu.edu),[ICM](http://icm.jhu.edu),[CIS](http://cis.jhu.edu),[Kavli](http://kndi.jhu.edu)}@[jhu](http://jhu.edu) -->

<!-- #### e: [jovo@jhu.edu](mailto:jovo@jhu.edu) | w:  -->
<!-- ### [NeuroData.io](http://neurodata.io) -->



#### these slides: <http://docs.neurodata.io/cs_slides.html>

<br>
<!-- [prof joshua t. vogelstein](http://jovo.me) -->

{[bme](http://www.bme.jhu.edu/),[icm](http://icm.jhu.edu/),[cis](http://cis.jhu.edu/),[idies](http://idies.jhu.edu/),kavli,[cs](http://engineering.jhu.edu/computer-science/), [ams](http://engineering.jhu.edu/ams/), [neuro](http://neuroscience.jhu.edu/)}@[jhu](https://www.jhu.edu/)

<br>

.center[please ask questions: [support@neurodata.io](mailto:support at neurodata dot io)!]



---
layout: true
.bbar[ _[Intro](#intro)_  | [Store](#store) | [Explore](#explore) | [Wrangle](#wrangle) | [Analyze](#anal)]
---




## 4 steps to discovery

<br/>

.center[
<img src="https://www.lucidchart.com/publicSegments/view/9cc4763f-5a2a-44df-bc0c-540316d6d62d/image.png" alt="Drawing" style="height: 250px;"/>
]

<br />

.center[Existing solutions are unable to elegantly handle 3D+ petascale data]




---

## [NeuroData](http://neurodata.io) meets needs to achieve

<br/>

.center[
<img src="https://www.lucidchart.com/publicSegments/view/4992c41b-3c24-48f1-8c7b-cd67641a2cdf/image.png" alt="Drawing" style="height: 250px;"/>
]



---

## Trade-offs at Each Step

<br />

| _Property_    | _Classical_ &nbsp;| _NeuroData_ &nbsp; | _Both_ |
| :---          | :----:      | :---:       | :---: |
| Quality     | .g[&check;]   | .r[&cross;] | .g[&check;] |
| Scalability | .r[&cross;]   | .g[&check;] | .g[&check;] |
| Capabilities| .g[&check;]   | .r[&cross;] | .g[&check;] |
| 1-clickiness| .r[&cross;]   | .g[&check;] | .g[&check;] |


--

<br />

.white[The ideal system will include both classical and novel NeuroData methods, as they complement one another.]







---

# Outline

<br />


<!-- 1. [Infrastructure](#infra) -->
3. [Store](#store)
4. [Explore](#explore)
5. [Wrangle](#wrangle)
7. [Analyze](#anal)


---
layout: true
.bbar[ [Intro](#intro)  | _[Store](#store)_ | [Explore](#explore) | [Wrangle](#wrangle) | [Analyze](#anal)]


---
name: store


## Store

<br />

- Databases
  - .y[ndstoredb]:   [Code](https://github.com/openconnectome/open-connectome) | [API](http://docs.neurodata.io/open-connectome/) | [Tutorials](http://docs.neurodata.io/open-connectome/sphinx/console.html) | [Manuscript](http://arxiv.org/abs/1306.3543) | [Docker](https://github.com/openconnectome/open-connectome//setup/Dockerfile) | [Setup](https://github.com/openconnectome/open-connectome/setup)  
      - [ndspdb](#store) 3D+ images and volumetric annotations: [Benchmarks](http://docs.neurodata.io/nddocs/more.html#r_store)
      - [ndramondb](#ndramondb) annotation metadata
  - [ndgrutedb](#ndgrutedb) Graphs with Rich attriBUTEs: [Web](http://openconnecto.me/graph-services/) | [Code](https://github.com/openconnectome/m2g/tree/master/MR-OCP)
- Utilities
  - [ndtilecache](#cdn) enables content distribution network: [Code](https://github.com/openconnectome/ocptilecache) | [API](http://docs.neurodata.io/ocptilecache/api/tilecache_api.html)
  - .y[ndlims] for managing additional metadata: [Code](https://github.com/openconnectome/ndlims) | [Demos](https://github.com/openconnectome/LIMS-Scripts)
  - .y[ndio] Python library for I/O: [Code](https://github.com/openconnectome/ndio) | [API](http://docs.neurodata.io/ndio/) | [Tutorials](http://docs.neurodata.io/nddocs/ndio/tutorials.html)
  - .y[CAJAL] MATLAB Toolbox for I/O & more: [Code](http://github.com/openconnectome/cajal) | [Docs](http://docs.neurodata.io/CAJAL/)
- [Hardware](#hardware)          






---
name: ndspdb

## Images: .y[ndspdb]

[Code](https://github.com/openconnectome/open-connectome) |
[Data Model](http://docs.neurodata.io/open-connectome/sphinx/datamodel.html) |
[Ingest](http://docs.neurodata.io/open-connectome/sphinx/ingesting.html) |
[Types](http://docs.neurodata.io/open-connectome/api/ocp_types.html) |
[API](http://docs.neurodata.io/open-connectome/) | [Manuscript](http://arxiv.org/abs/1306.3543) | [LIMS](https://github.com/openconnectome/ndlims) | [App](#r_infra)


.pull-left[
###  Storage Model
- Image Data Model to store images & associated metadata
- Dense multi-dimensional spatial array partitioned into cuboids
- Space filling curve minimizes the number of accesses
- Multi-resolution zoom pyramid
- 3rd party support: CATMAID, Viking, KNOSSOS, VAST, BigDataViewer
]

.pull-right[
![](https://upload.wikimedia.org/wikipedia/commons/3/3e/Moore3d-step3.png)
 ]




---
name: ndramondb

## Annotations: .y[ndramondb]


[Data Model](http://docs.neurodata.io/nddocs/ramon.html) |
[Code](https://github.com/openconnectome/open-connectome) | [API](http://docs.neurodata.io/open-connectome/api/ramon_api.html) |  [Tutorials](http://docs.neurodata.io/nddocs/ramonnd.html)
| [App](#r_anno)

.pull-left[
####  Data Model
  - ROI
  - Neuron
  - Segment
  - Skeleton
  - Synapse
  - Organelle
  - Node
]

.pull-right[
![](http://www.iva.dk/bh/Core%20Concepts%20in%20LIS/articles%20a-z/image008.jpg)
 ]





---
name: ndgrutedb

## Graphs: .y[ndgrutedb]

[Web](http://openconnecto.me/graphs) |
[Code](https://github.com/openconnectome/m2g/tree/master/MR-OCP)
| [App](#r_graphs)

.pull-left[
####  Data Model
  - Store graphs as edgelist
  - Metadata in csv
  - Supports the following types
   - Directed, undirected
   - Hypergraphs
   - Hierarchical graphs
   - Richly attributed graphs
  - Supports the following functions
    - convert
    - download
    - downsample
    - compute invariants
    - build from raw DTI data
]

.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/commons/9/9b/Social_Network_Analysis_Visualization.png" style="width: 350px;"/>
]


---
name: cdn

## CDN: .y[ndtilecache]

[Docs](http://docs.neurodata.io/ndtilecache/) |
[Code](https://github.com/neurodata/ndtilecache) |
[API](http://docs.neurodata.io/ndtilecache/api/tilecache_api.html)


<br>

.pull-left[
- Cache's image tiles for fast visualization
- Can deploy in AWS or locally
]



.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/en/thumb/7/77/Cdni_usage_example.png/600px-Cdni_usage_example.png" style="width: 350px;"/>
]

---
name: ndlims

## LIMS: .y[ndlims]

---
name: ndio

## Python Wrapper: .y[ndio]




---
name: hardware

## Data  Cluster

.center[
<img src="http://docs.neurodata.io/ndstore/_images/ocp_cluster.png" style="width: 700px;"/>
]

.pull-left[
- .y[Datascope] manages and stores spatial databases
- .y[CDN] provides "local" copies to individual regions
- .y[Local] user machines/clusters for  visualization & analysis
]

.pull-right[
- .y[AMI] Amazon Machine Instance to run terascale scale analyses: [Setup](http://docs.neurodata.io/nddocs/ami.html)
- .y[AWS Cluster] to build high-performance cluster to run petascale analyses (coming soon)
]

<!-- Head node serves as Web proxy and load balance
- Application Server nodes can perform cutout, propagate, and other Web-services
- Databases store Image DB and Tile Cache on SSD array
- Brainapps,  Brain Cloud, Awesome, Awesomer, Intel Phi, BrainViz (K80)
 -->



---
layout: true
.bbar[ [Intro](#intro)  | [Store](#store) | _[Explore](#explore)_ | [Wrangle](#wrangle) | [Analyze](#anal)]


---
name: explore


# Explore

<br>

- [Images](#ix)
- [Graphs](#gx)
- [Vectors](#vx)


---
name: ix

## Images: .y[Image Explorer (ix)]

[Web App](http://ix.neurodata.io) | [Code](https://github.com/openconnectome/NeuroDataViz) | [App](#r_explore)

.pull-left[
#### Highlights
- Uses [Leaflet.js](http://leafletjs.com/)
- Enables pan & zoom in 3D
- Supports multispectral data (4D)
- Supports time-series data (4D)
- Works on mobile & Web
- Image & Anno. Metadata
- Collaboration tools
### Examples
- [Volumetric annotation overlays](http://brainviz1.cs.jhu.edu/ndv/kharris15apical/em,ramon_test/3/507/469/90/)
- [Multispectral blending](http://brainviz1.cs.jhu.edu/ndv/project/Aratome15c_S17_W10/1/5818/527/0/)
- [Time-series](http://openconnecto.me/ocp/viz/freeman14/)
]

.pull-right[

<iframe allowtransparency="true" style="background: #FFFFFF;" src="http://brainviz1.cs.jhu.edu/ndv/kharris15apical/em,annos/2/1126/998/88/" frameborder="0" height="500" width="100%">
</iframe>
]




---
name: gx

## Graphs: .y[Graph Explorer (gx)]

[Web App](http://gx.neurodata.io) | [Code](https://github.com/neurodata/Graph-Explorer) 

.pull-left[
#### Highlights

- Shiny app
- Can load any graphml file, including attributes
- Calls [igraph](http://igraph.org/) in background

#### Functions

- Load or randomly sample graph
- Sample graph from many different random graph models
- Compute attributes of graph
- Plot graph
- Compute & plot graph statistics
- Find communities
- Save state

]

.pull-right[
<iframe allowtransparency="true" style="background: #FFFFFF;" src="http://gx.neurodata.io" frameborder="0" height="500" width="100%">
</iframe>
]



---

## Vectors: .y[Vector Explorer (vx)]

[Web App]((http://vx.neurodata.io) | [Code](https://github.com/neurodata/Vector-Explorer) | [Issues](https://github.com/neurodata/Vector-Explorer/issues)

.pull-left[
#### Highlights

- Shiny app
- Load csv file
- Interactive analysis with no coding req.

#### Functions

- Raw, z-scores, percentiles, etc.
- Heatmap of bi-clustered data
- Distributions of each feature
- Multivariate outlier detection
- Correlation & distance matrices
- Population statistics
- Dimensionality reduction
- Clustering

]
.pull-right[
<iframe allowtransparency="true" style="background: #FFFFFF;" src="http://shiny.neurodata.io/Vector-Explorer/" frameborder="0" height="500" width="100%">
</iframe>
]





---

layout: true
.bbar[ [Intro](#intro)  | [Store](#store) | [Explore](#explore) | _[Wrangle](#wrangle)_ | [Analyze](#anal)]


---
name: wrangle

# Wrangle

<br />

- streaming image processing
  - [2D stitching artifact](#2d)
  - [3D histogram normalization](#3d)
  - [volume registration](#ndreg)
- graph inference
  - [serial electron microscopy](#i2g)
  - [diffusion mri](#d2g)
  - [functional mri](#f2g)
- object detection
  - [label](#mana)
  - [learn](#maca)
  - [deploy](#maxa)

---
name: 2d

## 2D Stitching Artifact: .y[dmg]



.pull-left[

[Web](https://github.com/mkazhdan/DMG) | [Code](https://github.com/mkazhdan/DMG) | [Manuscript](http://www.cs.jhu.edu/~misha/MyPapers/ToG10.pdf) | [App](#r_pre)

- dmg = Distributed MultiGrid Poisson solver
- 2D image stitching histogram corrections
- Smoothing/Sharpening/High-Low Composting
]



.center[
<img src="images/original_zy.jpg" alt="Drawing" style="height: 200px;"/>
<img src="images/screened_zy.jpg" alt="Drawing" style="height: 200px;"/>
]



---
name: 3d

## 3D Color Correction: .y[gdf]

.pull-left[

[Web](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/) |  [Manuscript](http://arxiv.org/pdf/1506.02079v1.pdf) | [App](#r_3d)

- gdf = Gradient Domain Fusion
- 3D image histogram corrections
- Web-service coming soon
]



.center[
<img src="images/GDF2.png" alt="Drawing" style="width: 80%;"/>
]







---
name: ndreg

## Register Volume: .y[ndreg]


[Code](https://github.com/openconnectome/ndreg) | [Demo](https://github.com/openconnectome/ndreg/blob/master/maskPipelineExample.ipynb) | [Setup](https://github.com/openconnectome/ndreg/blob/master/README.md) | [App](#r_ndreg)

.pull-left[
#### Highlights

- Python wrapper for SimpleITK
- Open source [LDDMM](http://www.cis.jhu.edu/software/lddmm-volume/) nonlinear C implementation with Python bindings
- Integrated with .y[ndio]

<br />
]
.pull-right[
#### Functions

- Rigid, Affine, and Nonlinear
- Can apply to landmarks, masks, or images
- Includes automatic masking
- Quality control metrics
]




<img src="images/ndreg2.png" alt="Drawing" style="height: 225;"/>
<img src="images/ndreg.png"   alt="Drawing" style="height: 225px;"/>



.bottom[https://github.com/openconnectome/ndreg/blob/master/maskPipelineExample.ipynb]



---
name: i2g

## EM Graph Inference: .y[i2g]


---
name: d2g

## DTI Graph Inference: .y[ndmg]

---
name: f2g

## fMRI Graph Inference: .y[cpac]




---
name: mana

## Label: .y[mana]

[Docs](http://docs.neurodata.io/nddocs/mana.html) | [Code](https://github.com/openconnectome/ndparse/tree/master/mana)


.pull-left[
<!-- ## Wrangle: [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php) -->
1. Identify ROI
2. Use CAJAL/ndio to download data
3. run `mana_getImage.m` to get image
4. Annotate using [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php)
5. Save annotations
5. run `mana_putAnno.m` to put annotation database
]

.pull-right[
<!-- ## ND: ITK-SNAP + [mana](docs.neurodata.io/mana) -->
.center[
<img src="http://docs.neurodata.io/nddocs/ndparse/images/ndod/mana_itk_example.jpg"   alt="Drawing" style="height: 250px;"/>
]]



---
name: maca

## Learn: .y[maca]

[Docs](http://docs.neurodata.io/nddocs/maca.html) | [Code](https://github.com/openconnectome/ndparse/tree/master/maca)


.pull-left[
<!-- ## Wrangle: [ilastik](http://ilastik.org/) -->
- Get Data
- [ilastik](http://ilastik.org/) integration
- Visualize results
- ROC Curves
- Sweep over hyper-parameters
- Cross-validate
- Put Data

]

.pull-right[
<!-- ## ND: ilastic+CAJAL/ndio -->
.center[
<img src="http://docs.neurodata.io/nddocs/ndparse/images/ndod/maca_example.png"   alt="Drawing" style="height: 200px;"/>
]]




---
name: maxa

## Deploy: .y[maxa]

[App](#r_syn) | [Code](https://github.com/openconnectome/ndparse/tree/master/maxo)

<br />


.pull-left[
- Use [LONI Pipeline](http://pipeline.bmap.ucla.edu/)
- GUI to generate workflow connecting modules
- Each module calls a single executable
- Get Cubes for each worker node
- Each node processes data and spits out its answer
- CAJAL then merges them back together
- And sends back to database
]


.pull-right[
.center[
<img src="http://www.frontiersin.org/files/Articles/609/fninf-03-022/image_m/fninf-03-022-g002.jpg"    alt="Drawing" style="height: 250px;"/>
]]



---

layout: true
.bbar[ [Intro](#intro)  | [Store](#store) | [Explore](#explore) | [Wrangle](#wrangle) | _[Analyze](#anal)_]


---
name: anal


# Analyze

- [Images](#images)
- [Shapes](#shapes)
- [Graphs](#graphs)
- [Matrices](#matrices)


---
name: images

## Image Analysis
[Code](https://github.com/neurodata/ndstore/tree/master/stats) | [API](http://docs.neurodata.io/ndstore/api/stats_api.html)



.pull-left[

- Histogram
- Percentiles
- Mean
- Standard Deviation
]


<iframe allowtransparency="true" style="background: #FFFFFF;" src="http://brainviz1.cs.jhu.edu/tra/graphs/histogram.html" frameborder="0" height="350" width="100%">
</iframe>







---
name: shapes

## Shape Analysis: .y[ShapeSPH]
[Code](https://github.com/mkazhdan/ShapeSPH) 


.pull-left[

- Shape Spherical Harmonics
- [Shape Descriptions](http://htmlpreview.github.io/?https://github.com/mkazhdan/ShapeSPH/blob/master/descriptors.html)
- [Shape Alignment](http://htmlpreview.github.io/?https://github.com/mkazhdan/ShapeSPH/blob/master/alignment.html)
- [Shape Symmetry](http://htmlpreview.github.io/?https://github.com/mkazhdan/ShapeSPH/blob/master/symmetry.html)
]


.center[
<img src="images/shape_descriptor.png"    alt="Drawing" style="height: 250px;"/>
]




---
name: graphs

## Graph Analysis: .y[FlashGraph]


[Webpage](http://flashx.io) | [Code](https://github.com/icoming/FlashX)   | [AMI](http://www.flashgraph.net/documents/get_started2) | [Virtual Box](http://openconnecto.me/data/public/FlashGraph-VMs/) | [Setup](http://www.flashgraph.net/documents/get_started2) | [Manuscript](https://www.usenix.org/system/files/conference/fast15/fast15-paper-zheng.pdf)

.pull-left[
#### Highlights
- Store vertex state in memory, edge list on array of SSDs
- 1B vertex & 100B edge graphs
- R bindings for all functions
- Coming soon
  - [Joint  Embedding (w/missing values)](http://arxiv.org/abs/1502.03391)
  - [Nonpar 2-Sample Testing](http://arxiv.org/abs/1409.2344)
  - [Semipar 2-Sample  Testing](http://arxiv.org/abs/1403.7249)
  - [Vertex Clustering](http://arxiv.org/abs/1310.0532)
  - [Vertex Classification](http://arxiv.org/abs/1212.1182)
  - [Graph Matching](http://arxiv.org/abs/1405.3133)
  - [Hiearchical Modeling](http://arxiv.org/abs/1503.02115)
  - [Errorful Modeling](http://arxiv.org/abs/1211.3601)
]

.pull-right[
#### Graph Traversal Functions
-   Breadth-First Search
  - Triangle Counting
  - Connected Components
  - Scan Statistic
  - Page Rank
  - Community detection

]



---
name: matrices
## Matrix Analysis: .y[FlashMatrix]


[Webpage](http://flashx.io) | [Code](https://github.com/icoming/FlashX)   | [AMI](http://www.flashgraph.net/documents/get_started2) | [Virtual Box](http://openconnecto.me/data/public/FlashGraph-VMs/) | [Setup](http://www.flashgraph.net/documents/get_started2) | [Manuscript](https://www.usenix.org/system/files/conference/fast15/fast15-paper-zheng.pdf)

.pull-left[
#### Highlights
- Store vertex state in memory, edge list on array of SSDs
- 1B vertex & 100B edge graphs
- R bindings for all functions
- Coming soon
  - [Joint  Embedding (w/missing values)](http://arxiv.org/abs/1502.03391)
  - [Nonpar 2-Sample Testing](http://arxiv.org/abs/1409.2344)
  - [Semipar 2-Sample  Testing](http://arxiv.org/abs/1403.7249)
  - [Vertex Clustering](http://arxiv.org/abs/1310.0532)
  - [Vertex Classification](http://arxiv.org/abs/1212.1182)
  - [Graph Matching](http://arxiv.org/abs/1405.3133)
  - [Hiearchical Modeling](http://arxiv.org/abs/1503.02115)
  - [Errorful Modeling](http://arxiv.org/abs/1211.3601)
]

.pull-right[
#### Matrix Functions
  - PageRank
  - Eigendecomposition
  - Singular Value Decomposition
  - K-means
  - Non-negative matrix factorization (NMF)
]






---
layout: false

# References

<br />


1. Burns B et al. [The Open Connectome Project Data Cluster: Scalaballe Analysis and Vision for High-Throughput Neuroscience](http://arxiv.org/abs/1306.3543).  Scientific and Statistical Database Management (SSDBM), 2013.

1. Burns B, Vogelstein JT, Szalay AS. [From Cosmos to Connectomes: the Evolution of Data-Intensive Science](http://www.sciencedirect.com/science/article/pii/S0896627314007466). Neuron, 2015.

---

class:  center

# NeuroData Family

<br />

.center[
.small[
|   |   | |
| :--- | :--- | :--- |
| Store | | Randal Burns, Eric Perlman, Kunal Lillaney, Priya Manavalan, Alex Eusman
| Explore | | .orange[Misha Kazhdan, Alex Baden, Jordan Matelsky]
| Wrangle | | .y[Mike Miller, Micholas Charon, Kwame Kutten, Greg Kiar, Eric Bridgeford, Greg Hager, Will Gray Roncal, Mark Chevillet,  Deank Kleissas, R. Jacob Vogelstein, Guillermo Sapiro, Anish Simhal, Konrad Kording, Eva Dyer]
| Analyze | | .blue[Joshua T. Vogelstein, Carey Priebe, Dan Naiman,  Tyler Tomita, Youngser Park, Cencheng Shen, Ivan Kuznetsov,Da Zheng, Disa Mhembere, Vince Lyzinski, Avanti Athreya, Daniel Sussman, Shangsi Wang, Runze Tang, Minh Tang]
| Love | | .pink[yummy, family, friends, earth, universe, multiverse?]
]]


---
class:   center


# Questions?

<!-- ### Funding &nbsp;&nbsp;&nbsp;&nbsp;   -->

<br />

_____

Funding


NIH: TRA

NIH/NSF:  {BIGDATA, CRCNS}

DARPA: {XDATA,GRAPHS,SIMPLEX}


____


w: [neurodata.io](http://neurodata.io)

d: [docs.neurodata.io](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io)


____


[more slides](http://docs.neurodata.io/ndintro/more.html)





    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();

      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });

      MathJax.Hub.Configured();

      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '4:3',

        // Navigation options
        navigation: {
          // Enable or disable navigating using scroll
          // Default: true
          // Alternatives: false
          scroll: true,

          // Enable or disable navigation using touch
          // Default: true
          // Alternatives: false
          touch: true,

          // Enable or disable navigation using click
          // Default: false
          // Alternatives: true
          click: false
  },

  // Customize slide number label, either using a format string..
  // slideNumberFormat: 'Slide %current% of %total%',
  // .. or by using a format function
  slideNumberFormat: function (current, total) {
    return  current + ' / ' + total;
  },

  // Enable or disable counting of incremental slides in the slide counting
  countIncrementalSlides: false
});
    </script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
  </body>
</html>
